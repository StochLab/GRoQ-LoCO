<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="">
  <meta name="keywords" content="GROQLoco, Behavior cloning, Quadrupeds, Generalization, Zero-shot-transfer, Offline dataset">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title></title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/stochlab.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <img src="./static/images/final_logo.png" width="20%" alt="Stoch Lab Logo"/>
        <!-- <img src="./static/images/IISc_Logo.jpg" width="10%" alt="IISc Logo" align="right"/> -->
        <img src="./static/images/iisc_logo.png" width="11%" alt="IISc Logo" align="right"/>
        <div class="columns is-centered"></div>
      </div>
    </div>
  </section>
  
  <section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">        
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">GRoQ-Loco: Generalist and Robot-agnostic Quadruped Locomotion Control using Offline Datasets</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://narayananpp.github.io/">Narayanan PP</a>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/sarvesh-prasanth-v/">Sarvesh Prasanth Venkatesan</a>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/sri-k08/">Srinivas Kantha Reddy</a>,
            </span>
            <span class="author-block">
              <a href="https://www.shishirny.com/">Shishir Kolathaya</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"> Indian Institute of Science (IISc), Bangalore </span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              
              <span class="link-block">
                <a href="https://arxiv.org/abs/2505.10973"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=Iq00fYSHmBo"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>

              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://www.github.com/StochLab/GRoQ-Loco"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
            </div>
          </div>

          <!-- Under Review Text -->
          <div class="is-size-6 publication-authors">
            <span class="author-block"> (Preprint under review) </span>
          </div>

          <div class="column has-text-centered">
            <iframe width="720" height="405"
                src="https://www.youtube.com/embed/Iq00fYSHmBo"
                title="Demo Video"
                frameborder="0"
                allowfullscreen>
            </iframe>
          </div>


      </div>
    </div>
  </div>
</section>


<section class="hero is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Recent advancements in large-scale offline training have demonstrated the potential of generalist policy learning for complex robotic tasks. However, applying these principles to legged locomotion remains a challenge due to continuous dynamics and the need for real-time adaptation across diverse terrains and robot morphologies. In this work, we propose GRoQ-Loco, a scalable, attention-based framework that learns a single generalist locomotion policy across multiple quadruped robots and terrains, relying solely on offline datasets. Our approach leverages expert demonstrations from two distinct locomotion behaviors - stair traversal (non-periodic gaits) and flat terrain traversal (periodic gaits) - collected across multiple quadruped robots, to train a generalist model that enables behavior fusion for both behaviors. Crucially, our framework operates directly on proprioceptive data from all robots without incorporating any robot-specific encodings. The policy is directly deployable on an Intel i7 nuc, producing low-latency control outputs without any test-time optimization. Our extensive experiments demonstrate strong zero-shot transfer across highly diverse quadruped robots and terrains, including hardware deployment on the Unitree Go1, a commercially available 12kg robot. Notably, we evaluate challenging cross-robot training setups where different locomotion skills are unevenly distributed across robots, yet observe successful transfer of both flat walking and stair traversal behaviors to all robots at test time. We also show preliminary walking on Stoch 5, a 70kg quadruped, on flat and outdoor terrains without requiring any fine tuning. These results highlight the potential for robust generalist locomotion across diverse robots and terrains.
            </p>
            <br>
          </div>
        </div>
      </div>
    </div>  
  </div>
</section>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">Contributions</h2>
        </div>
      </div>
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <div class="content has-text-justified" style="padding-top: 3%">
            <ul>
              <li><b>A Generalist Locomotion Controller:</b> We develop a single policy that controls multiple distinct quadrupedal robots without requiring robot-specific information.</li>
              <li><b>Offline Multi-Behavior Learning:</b> We demonstrate that purely offline training on diverse motion data produces a policy with periodic gaits and multi-terrain traversibility.</li>
              <li><b>Zero-Shot Transfer and Robustness:</b> Our framework achieves strong zero-shot transfer across diverse quadruped robots and terrains, including hardware deployment on commercial platforms like the Unitree Go1 and the Stoch 5, without requiring fine-tuning.</li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

  <section class="hero is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column" style="padding-bottom: 3%">
          <h2 class="title is-3">Training Architecture</h2>
        </div>
      </div>

      <div class="has-text-centered">
        <figure style="margin-bottom: 2%;">
          <img src="images/GROQLoco_datagen.png" alt="Data Generation" width="70%">
          <figcaption style="font-size: 0.9em; margin-top: 0.5em;">
            Figure 1: Offline data generation pipeline used in GRoQ-Loco, illustrating trajectory collection from expert RL policies on diverse terrains and robot morphologies.
          </figcaption>
        </figure>

        <figure>
          <img src="images/GrocLoco_model_diagram.jpg" alt="Model Diagram" width="70%">
          <figcaption style="font-size: 0.9em; margin-top: 0.5em;">
            Figure 2: Model architecture of GRoQ-Loco, showing the sequential processing pipeline with observation encoding, causal attention, GRU-based temporal modeling, and MLP action prediction.
          </figcaption>
        </figure>

        <p class="content has-text-justified" style="padding-top: 5%">
          Expert demonstrations are collected in Isaac-Gym simulation across morphologically diverse quadruped platforms using two specialized controllers—a <b>periodic gait controller for flat terrain</b> and a <b>non-periodic controller for stairs</b>. GRoQ-Loco integrates causal multi-head attention mechanisms before and after a GRU core to enhance temporal representation learning. Observation embeddings and GRU hidden states are contextually refined to produce smooth and adaptive actions across diverse robot morphologies and terrains. Zero-shot generalization is showcased on robots including Unitree Go1, B1 and B2, Stoch5, Stoch3, Aliengo, X30, and Lite3.
        </p>
      </div>


    </div>
  </div>
</section>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column" style="padding-bottom: 3%">
          <h2 class="title is-3"> Experiments </h2>
        </div>
      </div>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">

          <div style="display: flex; justify-content: center; align-items: flex-start; gap: 2%;">
            <figure style="width: 55%;">
              <img src="images/results/stair_expts.png" alt="Stair Experiments" style="width: 100%;">
              <figcaption style="font-size: 0.9em; padding-top: 0.5em;">
                Table 1: Evaluation on stair environments with increasing difficulty (13–29 cm step heights).
              </figcaption>
            </figure>

            <figure style="width: 40%;">
              <img src="images/results/slope_expts.png" alt="Slope Experiments" style="width: 100%;">
              <figcaption style="font-size: 0.9em; padding-top: 0.5em;">
                Table 2: Zero-shot slope traversal results.
              </figcaption>
            </figure>
          </div>

          <div class="content has-text-justified" style="padding-top: 5%">
            <p>
              We evaluate our generalist policy across five settings, spanning multiple quadruped robots and terrain types—flat ground, stairs, and slopes—with data sparsely distributed across this space.
              <br><br>
              <b>Zero-Shot Skill and Robot Transfer.</b> Our policy generalizes to unseen robot morphologies and terrains without any fine-tuning, demonstrating effective knowledge transfer. Robots not seen during training successfully walk, climb stairs, and traverse slopes in a zero-shot setting.
              <br><br>
              <b>Out-of-Distribution Generalization.</b> Despite training only on stairs up to 17 cm step height, policies succeed on both smooth and irregular inclines up to 40° and on unseen stair geometries beyond the training range, showing emergent base stabilization and terrain adaptation.
              <br><br>
              <b>Cross-Robot Skill Sharing.</b> Robots that only contributed flat-terrain data exhibit robust stair traversal. This highlights effective generalization enabled by shared locomotion structure.
              <br><br>
              <b>Real-World Deployment Without Tuning.</b> Policies trained entirely in simulation are deployed directly on hardware (Go1, Stoch5), demonstrating successful flat, stair, and slope traversal in real-world conditions.
              <br><br>
              Check out our paper for more details.
            </p>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">    
      <div class="columns is-centered has-text-centered">
          <div class="column" style="padding-bottom: 3%">
            <h2 class="title is-3"> Results</h2>
          </div>
      </div>

      <div class="columns is-centered has-text-centered">
        <div class="column" style="padding-top: 5%">
          <h2 class="title is-5"> Zero-shot stair climbing across morphologies </h2>
        </div>
      </div>

      <div class="columns is-centered">
        <img src="images/results/sim1_cp.gif" width="39%" style="padding-right: 2%">
        <img src="images/results/sim2_cp.gif" width="39%" style="padding-left: 2%">
      </div>

      <div class="columns is-centered has-text-centered" style="padding-top: 5%">
        <div class="column">
          <h2 class="title is-5">Go1 Zero-shot on stairs and slopes</h2>
        </div>
      </div>

      <div class="columns is-centered">
        <img src="images/results/stair_go1.gif" style="width: 39%; padding-right: 2%;">
        <img src="images/results/slope_go1.gif" style="width: 39%; padding-left: 2%; height: 50%; object-fit: contain;">
      </div>

      <div class="columns is-centered has-text-centered">
        <div class="column" style="padding-top: 5%">
          <h2 class="title is-5"> Stoch5 Zero-Shot Flat Terrain Locomotion (Preliminary Hardware Results) </h2>
        </div>
      </div>

      <div class="columns is-centered">
        <img src="images/results/flat_stoch5.gif" width="39%" style="padding-right: 2%">
      </div>

    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-5">Cite</h2>
    <pre><code>
        @misc{pp2025groqlocogeneralistrobotagnosticquadruped,
              title={GRoQ-Loco: Generalist and Robot-agnostic Quadruped Locomotion Control using Offline Datasets},
              author={Narayanan PP and Sarvesh Prasanth Venkatesan and Srinivas Kantha Reddy and Shishir Kolathaya},
              year={2025},
              eprint={2505.10973},
              archivePrefix={arXiv},
              primaryClass={cs.RO},
              url={https://arxiv.org/abs/2505.10973},
        }
    </code></pre>
  </div>
</section>


<!--<footer class="footer">-->
<!--  <div class="container">-->
<!--    <div class="content has-text-centered">-->
<!--      <a class="icon-link" href="https://github.com/StochLab" class="external-link" disabled>-->
<!--        <i class="fab fa-github"></i>-->
<!--      </a>-->
<!--    </div>-->
<!--  </div>-->
<!--</footer>-->

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://github.com/StochLab" target="_blank" rel="noopener noreferrer">
        <i class="fab fa-github"></i>
      </a>
      <a class="icon-link" href="https://discord.gg/your-discord-invite" target="_blank" rel="noopener noreferrer">
        <i class="fab fa-discord"></i>
      </a>
    </div>
  </div>
</footer>


</body>
</html>
